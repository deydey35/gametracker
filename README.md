Voici le contenu complet de ton fichier **README.md**, nettoyÃ© de toute citation et prÃªt Ã  Ãªtre utilisÃ© pour ton rendu final.

---

# ğŸ® GameTracker - Pipeline ETL AutomatisÃ©

## ğŸ“ PrÃ©sentation du projet

GameTracker est une startup spÃ©cialisÃ©e dans l'analyse des performances des joueurs de jeux vidÃ©o. Ce projet consiste Ã  mettre en Å“uvre un pipeline **ETL** (Extract, Transform, Load) robuste et conteneurisÃ© pour traiter des donnÃ©es brutes de profils de joueurs et de sessions de jeu.

L'objectif est de transformer des fichiers CSV "sales" en une base de donnÃ©es MySQL propre et d'en extraire un rapport de synthÃ¨se analytique automatique.

---

## ğŸ› ï¸ ProblÃ¨mes de qualitÃ© traitÃ©s

Le pipeline dÃ©tecte et corrige les **7 problÃ¨mes de qualitÃ©** identifiÃ©s dans les donnÃ©es sources :

1. **Doublons** : Suppression des joueurs (via le pseudo) et des scores (via l'ID) apparaissant plusieurs fois.
2. **Emails invalides** : Identification et invalidation des adresses ne contenant pas de caractÃ¨re `@`.
3. **Dates incohÃ©rentes** : Normalisation des formats variÃ©s (ISO, FR, etc.) via une conversion robuste.
4. **Espaces parasites** : Nettoyage des espaces en dÃ©but et fin de certains noms d'utilisateur.
5. **Scores nÃ©gatifs** : Suppression des scores aberrants (nÃ©gatifs ou nuls).
6. **Valeurs manquantes** : Traitement des champs vides pour les emails ou les scores.
7. **RÃ©fÃ©rences orphelines** : Suppression des scores liÃ©s Ã  un `player_id` inexistant dans le fichier des joueurs.

---

## ğŸ“ Structure du projet

L'arborescence respecte l'organisation suivante pour garantir la modularitÃ© du code :

```text
gametracker/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/               # DonnÃ©es brutes 
â”‚       â”œâ”€â”€ Players.csv
â”‚       â””â”€â”€ Scores.csv
â”œâ”€â”€ output/                # Dossier des rapports gÃ©nÃ©rÃ©s 
â”œâ”€â”€ scripts/               # Scripts d'automatisation et SQL
â”‚   â”œâ”€â”€ init-db.sql
â”‚   â”œâ”€â”€ run_pipeline.sh
â”‚   â””â”€â”€ wait_for_db.sh
â”œâ”€â”€ src/                   # Code source Python (ETL)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ load.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ report.py
â”‚   â””â”€â”€ transform.py
â”œâ”€â”€ .gitignore             # Fichiers exclus du versionnement
â”œâ”€â”€ docker-compose.yml     # Orchestration des services MySQL et App
â”œâ”€â”€ Dockerfile             # Configuration de l'image de l'application
â”œâ”€â”€ README.md              # Documentation du projet
â””â”€â”€ requirements.txt       # DÃ©pendances Python 

```

---

## PrÃ©requis

* Docker et Docker Compose installÃ©s et fonctionnels.
* AccÃ¨s rÃ©seau pour la construction (build) de l'image Python.

---

## Construction et dÃ©marrage des services

Pour lancer l'intÃ©gralitÃ© du pipeline, exÃ©cutez la commande suivante Ã  la racine du projet :

```bash
docker compose up --build -d

```

### ğŸ” DÃ©tails de l'automatisation

Cette commande suffit Ã  elle seule pour piloter le projet. C'est le "bouton de dÃ©marrage" qui permet d'orchestrer la mise en place de l'environnement multi-services en une seule action :

1. **Build** : Elle construit l'image de l'application en installant le client MySQL et les dÃ©pendances Python.
2. **Orchestration** : Elle dÃ©marre la base de donnÃ©es et attend qu'elle soit opÃ©rationnelle (`service_healthy`) avant de lancer l'application.
3. **ExÃ©cution automatique** : Une fois lancÃ©e, elle dÃ©clenche le script `run_pipeline.sh` qui initialise les tables SQL, exÃ©cute le pipeline ETL Python et gÃ©nÃ¨re le rapport final dans `output/rapport.txt`.

